Q: Consider a PySpark DataFrame named "transactions" with columns "transaction_id", "user_id", and "amount". Write a code to calculate the average transaction amount for each user and display the result.

A:

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
spark = SparkSession.builder.appName("Mock Test").getOrCreate()

schema = "transactio_id INT, user_id INT, amount INT"
df = spark.read.csv("transactions.csv", header = True, schema = schema)
new_df = df.groupBy("user_id").avg("amount")
new_df.show()